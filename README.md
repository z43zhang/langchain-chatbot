# ğŸŒ **Live Demo**: [Click here to try it out](https://zhang-chatbot.streamlit.app/)

![App Preview](https://github.com/z43zhang/langchain-chatbot/blob/main/assets/main1.png)

### > **TL;DR**: A multi-turn RAG chatbot over [LangChain documentation](https://python.langchain.com/), built with GPT-4o, Pinecone, and LangChainâ€™s modular chain framework. 


---

# ğŸš€ Features

* ğŸ” **LangChain RAG Pipeline** â€” Uses `HistoryAwareRetriever`, `StuffDocumentsChain`, and `RetrievalChain` from LangChain
* ğŸ”„ **Multi-Turn Query Handling** â€” Rephrases follow-ups using chat context via `chat-langchain-rephrase` and `HistoryAwareRetriever`
* ğŸ§  **Semantic Search Index** â€” Embeds 2,383 chunks with `text-embedding-3-small` (1536-dim) and stored in Pinecone
* ğŸ—‚ï¸ **Custom Document Ingestion** â€” Scrapes LangChain docs via Firecrawl API and chunked via `RecursiveCharacterTextSplitter`
* ğŸ“ˆ **LangSmith Monitoring** â€” Logs retriever, prompt, and LLM steps with full RAG pipeline traces
* ğŸ”— **Source Attribution** â€” Cites original documentation URLs used for each response
* ğŸ§¬ **Deterministic Chunk IDs** â€” Prevents duplicate uploads using UUIDv5 + MD5 hashing of content
* ğŸ¤– **Grounded Generation** â€” Uses `GPT-4o-mini` to generate answers strictly from retrieved context via `retrieval-qa-chat`
* ğŸ–¥ï¸ **Interactive Chat App** â€” Streamlit UI with avatars, timestamps, real-time responses, reset, and download options

---

# ğŸ› ï¸ Tech Stack

| Layer            | Tools / Libraries                                      |
|------------------|--------------------------------------------------------|
| RAG Framework    | LangChain (`Retriever`, `Chains`, `Prompt Hub`)        |
| LLM + Embedding  | OpenAI `gpt-4o-mini`, `text-embedding-3-small`         |            
| Vector DB        | Pinecone                                               |
| Monitoring       | LangSmith                                              |
| Web Scraper      | Firecrawl API                                          |
| Chunking         | `RecursiveCharacterTextSplitter`                       |
| UUID Hashing     | `uuid`, `hashlib`                                      |
| Prompt Templates | LangChain Hub                                          |
| UI & Deployment  | Streamlit Cloud                                        |

---

# ğŸ”¬ Project Breakdown

This section follows the full life cycle: data ingestion â†’ RAG pipeline â†’ UI deployment.

## 1. ğŸ“¥ Ingest Documentation 

The ingestion pipeline scrapes and prepares LangChain docs for semantic search:

- **Data Source**: LangChain documentation URLs
- **Crawling Tool**: `FirecrawlApp().crawl_url()`
  - Supports both Markdown and HTML output formats
- **Chunking**: 
  - Tool: `RecursiveCharacterTextSplitter`  
  - Config: `chunk_size=800`, `chunk_overlap=100`
- **UUID Hashing**: 
  - Generates deterministic chunk IDs using `uuid5(NAMESPACE_URL, MD5(content))`  
  - Prevents duplicates during repeated runs
- **Embedding**: 
  - Model: `text-embedding-3-small` (OpenAI)
  - Dimensions: 1536
- **Storage**: 
  - Vector store: `PineconeVectorStore`
  - Record Count: 2383

> âœ… Output: A Pinecone index filled with chunked and deduplicated documentation vectors.

---

## 2. ğŸ”§ RAG Pipeline

This module handles backend processing for user queries using LangChainâ€™s chain API.

### ğŸ”¹ Retriever
   - Wraps Pineconeâ€™s retriever in a `HistoryAwareRetriever`  
   - Uses the prompt `chat-langchain-rephrase` from LangChain Hub to convert follow-up queries into standalone ones

### ğŸ”¹ Document Combiner  
   - Uses `StuffDocumentsChain` with `retrieval-qa-chat` prompt  
   - Merges retrieved documents + user query â†’ formatted prompt for LLM

### ğŸ”¹ Retrieval Chain
   - Uses `create_retrieval_chain()` to link retriever + combiner  
   - Input: `query`, `chat_history`  
   - Output: `result["answer"]`, `result["context"]`

> âœ… Output: A structured dictionary containing the final answer and source documents.

---

## 3. ğŸ’¬ Streamlit App 

This is the front-end entry point that drives user interaction.

- `st.session_state` persist:
  - User inputs
  - Assistant responses
  - Chat history for multi-turn context
  - Timestamps for each message
- Captures input from `st.chat_input()`
- Records user timestamp
- Sends input to `run_llm()` (calls backend pipeline)
- Formats output:
  - Appends sources via `create_sources_string()`
  - Adds assistant timestamp
- Displays chat messages with avatars (`ğŸ§‘â€ğŸ’»` for user, `ğŸ¤–` for assistant)
- Provides:
  - ğŸ”„ Reset chat button (clears session state)
  - ğŸ–¨ï¸ Download chat history as `.txt`

> âœ… Output: A live conversational UI backed by a real-time RAG pipeline with full session memory and source transparency.

---

# ğŸ§ª Examples

These examples demonstrate how the chatbot handles single-turn queries, multi-turn conversation flow, and provides transparent source attribution â€” with supporting LangSmith visualizations.

## Example 1: ğŸ“Œ Single-Turn Query

A question about a LangChain component.
![App Preview](https://github.com/z43zhang/langchain-chatbot/blob/main/assets/main2.png)

### âš™ï¸ Under The Hood

LangSmith trace for the question _â€œWhat is a document loader?â€_. 

![App Preview](https://github.com/z43zhang/langchain-chatbot/blob/main/assets/rag.png)

This shows how relevant context is retrieved, formatted, and passed to `gpt-4o-mini`, resulting in a grounded response.

## Example 2: ğŸ“Œ Follow-Up Understanding

A vague follow-up is reinterpreted based on chat history.

![App Preview](https://github.com/z43zhang/langchain-chatbot/blob/main/assets/history1.png)

### âš™ï¸ Under The Hood

The chatbot rewrites the query "Give me an example" into _"Can you provide an example of a document loader?"_ using `HistoryAwareRetriever`.

![App Preview](https://github.com/z43zhang/langchain-chatbot/blob/main/assets/rewriting.png)

This demonstrates that the system understands conversation flow, not just isolated prompts.

## Example 3: ğŸ“Œ Source Traceability

Each answer includes links to retrieved document chunks used in generation.

![App Preview](https://github.com/z43zhang/langchain-chatbot/blob/main/assets/source.png)

---

# ğŸ§‘â€ğŸ’» Run Locally

```bash
git clone https://github.com/z43zhang/langchain-rag-chatbot.git
cd langchain-rag-chatbot
pipenv install 

# Add your OpenAI key, Pinecone key, and Firecrawl key to a .env file

# Ingest Documentation
pipenv run python ingest_documents.py

# Launch the App
streamlit run app.py
